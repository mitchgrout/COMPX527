\documentclass[conference]{IEEEtran}
\usepackage[utf8]{inputenc}

\title{COMPX527 Assignment 1 Report}

\author{
\IEEEauthorblockN{Glenn Cumming}
\IEEEauthorblockA{Department of Computer Science\\
  \textit{University of Waikato}\\
  Hamilton, New Zealand\\
  \texttt{glenn@hif.nz}}
  \and
\IEEEauthorblockN{Mitchell Grout}
\IEEEauthorblockA{Department of Computer Science\\
  \textit{University of Waikato}\\
  Hamilton, New Zealand\\
  \texttt{mjg44@students.waikato.ac.nz}}
  \and
\IEEEauthorblockN{Shufen Li}
\IEEEauthorblockA{Department of Computer Science\\
  \textit{University of Waikato}\\
  Hamilton, New Zealand\\
  \texttt{sl302@students.waikato.ac.nz}}
  \and
\IEEEauthorblockN{YingJun Huang}
\IEEEauthorblockA{Department of Computer Science\\
  \textit{University of Waikato}\\
  Hamilton, New Zealand\\
  \texttt{yh320@students.waikato.ac.nz}}
}
\begin{document}

\maketitle

\begin{abstract}
Abstract Text
\end{abstract}
\begin{IEEEkeywords}
AWS, COMPX527
\end{IEEEkeywords}
\section{Solution Summary}
Solution Summary
\section{Motivation}
We decided on object detection in the cloud in order to learn and appricate the challenges of providing a stateless, scalbale service that could be used for a variey of other projects. Examples included
\begin{itemize}
\item Contexutal threat analysis, such as humans detected in an area which should only include livestock.
\item Numbercial anyalisis, such as the number of a species of wildlife in an area over time.
\item Absence detection, indetifying objects that should be in an image but are not
\end{itemize}
\section{Proposed Solution}
In order to 
\section{Solution Architecture}
Solution Architecture
\subsection{The Image Processing Container}
The project uses the Darknet neural net fork by AlexeyAB
\footnote{https://github.com/AlexeyAB/darknet}
pre-trained on the COCO AWS images in context set. A Dockerfile generated the container template.
This container uses the Darknet web server provided by komorin0521
\footnote{https://github.com/komorin0521/darknet\_server}
to create a web service that can be run on EC2 instances.
\subsection{The Load Balancer}
The object detection being inhernetly slow forces the use of laod balancing and scaling techniques. Using the AWS Elastic Load Balancer allowed us balance the HTTP requests over two or more EC2 servers running the Darknet servers. We could create as many Darknet servers as we wished, although of course this lent itself to waisted compute resources. Though we had great sucess using AWS AutoScaling Groups, which allows a lower and upper limit of EC2 instances running our Darknet server to be defined, this functionality was not avalible in the student accounts.
\subsection{The Web User Interface}
In order to have a better demo, it was decided to go ahead and produce a web site interface that would allow uploading 
\subsection{The Web API}
The intended standard way to interact with the Darknet Object Detection Cluster is to access it via HTTP calls using the url http://\textless load\_balancer\_fqdn\textgreater/detect. As the system is inteneded for the use of non-private images no ssl was implemented on the load balancer, though it is supported.
The code submitted for this project includes \textit{simple\_upload.py} and \textit{forked\_upload.py}, which are Python 3 examples for using the HTTP API.
\section{Development}
\subsection{Technology}
\paragraph{Darknet}
Darknet is an open source object detection neural net. This technology was chosen for the following reasons.
\begin{itemize}
\item Open Source
\item Features both Nvidia GPU and AVX2 compliation options. The AVX2 instruction set is avalible on all EC2 instances, so we compiled for it. If we wished to use the Keplar GPU P2 instances, then we could compile for it.
\item Provides the Yolo3 data set. Yolo 3 is a pretrained on the COCO object detection, segmentation, and captioning dataset avaliable on the Registry of Open Data on AWS \footnote{https://registry.opendata.aws/fast-ai-coco/}
\end{itemize}
\paragraph{Terraform}
Terraform was given in as an example of the provisioning service to use in this assignment. AWS CloudFormation was another option suggested. The decision to go with terraform rather than CloudFormation was based on the following
\begin{itemize}
  \item CloudFormation is prioritory and is specific to AWS cloud offierings TODOREF. Though this assigmnet is on a small and temporty scale, we still not want to use a technology that would create vendor lockin
  \item Terraform supports provisioning many different platforms, both open source stand priopritary, such as Azure, Goolge Cloud, Kubernetes and OpenStack \footnote{https://aws.amazon.com/cloudformation/}. Developng expericne in deployments with terraform therefore was demied to be more useful.
\end{itemize}
\paragraph{Ansible}
Though Terraform is capable of running commands post-install in order to install services and other software needed for our cluster, our cluster used Ansible playbooks instead. Though it meant learning another technology, we demeed a good use of our time since:
\begin{itemize}
  \item Terraform can only run scripts, which would have to be created.
  \item Ansible's langauge is very flxible and is created specifally for the purpose of delpoymnet.
  \item This is a recommended approach by HashiCorp, the devlopers of Terraform. \footnote{https://www.hashicorp.com/resources/ansible-terraform-better-together}
\end{itemize}
\paragraph{Docker}
Darknet and Darknet Server are in active development and therefore potentially unsrtanble. In order to create a stable service that could be deployed easily we chose Docker containers to package together the different software. \footnote{https://www.docker.com/resources/what-container}. We could have alternatively created custom installtion/deployment scripts or generated OS packages such as dpkg and rpm \footnote{https://www.tecmint.com/linux-package-management/}. However part of the flexibility of Docker is that we could deploy it on multiple different platforms if the need arose, and we found setting up the Dockerfile was a straight forward process for our needs.
\subsection{Compairsion with existing object detection soltutions}
Amazon Rekognition
\section{Security Assessment}
Security Assessment
\subsection{Data Security}
The Darknet Object Detection Cluster was specifically created to be stateless and public. Interception of HTTP requests and results can be easily interceptied by third parties with access to the networks between the client and the service.
\subsection{Access Security}
Access Security
\subsection{Network Security}
Network Security
\subsection{Vulnerability Assessment}
\subsection{Monitoring}
AWS EC2 instance monitoring was enabled during the terraform creation of the cluster. Future development of the cluster would likely use additional monitoring of performance, costs and uptimes using dedicated EC2 instances, and such existing monitoring systems as Icinga, Promethues and Munin. Uptime moniroing would of nessescity be run etxernally, such as on internal machines or another cloud providers offering.
\section{Actual AWS Expenditure}
TODO
\section{Future Improvements}
\paragraph{Docker}
Docker was chosen for simplicity and flexibility; however, if the product was to be further developed it would benefit being deployed as dpkg or rpm with proper dependencies from its own repository, allowing for both easier installtion and updates.
\paragraph{HTTP}
The service is stateless, plublic and insecure. If a layer of security is desired to protect the data in transit, then HTTPS can be added to the Elastic Load Balancer via the AWS Certificate Manager \footnote{https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/ssl-server-cert.html}.
\section{Team Members Contributions}
\section{Assignment Requirements Completion}
\section{Standards}
This report was created in LaTex using the IEEEtran document class provided by IEEE template avaliable at
\footnote{https://www.ieee.org/conferences/publishing/templates.html}
, and generated into PDF by Gnome LaTeX
\footnote{https://wiki.gnome.org/Apps/GNOME-LaTeX}
.
\end{document}
